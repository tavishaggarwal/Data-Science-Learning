{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import numpy as np\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdbDataSet = pd.read_csv('tmdb_5000_movies.csv')\n",
    "avocadoDataSet = pd.read_csv('avocado.csv')\n",
    "del avocadoDataSet['Unnamed: 0'] # removing unwanted column from dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract basic information about dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returning top 5 rows\n",
    "print(tmdbDataSet.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returning last row\n",
    "print(tmdbDataSet.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting info about dataset like clolumn types, count of not null values\n",
    "print(tmdbDataSet.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to check datatypes of the columns\n",
    "print(tmdbDataSet.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the columns in dataset\n",
    "print(tmdbDataSet.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the shape of dataset\n",
    "print(tmdbDataSet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information like count, mean, std, min, 25%, 50%, 75% and max of dataset\n",
    "print(tmdbDataSet.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calulate 55% of the dataset\n",
    "print(tmdbDataSet.vote_count.quantile([0.55]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output is same as that of above cell\n",
    "temp = tmdbDataSet.sort_values(['vote_count']).head(2641)\n",
    "print(temp.vote_count.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate median of the dataset\n",
    "print(tmdbDataSet.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing null values\n",
    "As we observed that out of 4803 rows only 1712 are the not null values for the homepage column. Let's investigate it further and check why these column have null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdbDataSet[tmdbDataSet['homepage'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the unique values of the column \n",
    "print(tmdbDataSet.production_countries.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmdbDataSet.spoken_languages.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmdbDataSet.release_date.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting data type of the column\n",
    "As we have seen above that status column have only 3 distinct values. So it would be feasible to convert the column data type to category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting datatype of column to category\n",
    "tmdbDataSet['status'] = tmdbDataSet['status'].astype('category')\n",
    "print(tmdbDataSet.status.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command used to convert data type to numeric\n",
    "# Note that below command will give an error while executing as string cannot be converted to numeric\n",
    "tmdbDataSet['status'] = pd.to_numeric(tmdbDataSet['status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To forcefully convert column to numeric. It will insert NaN for the values it cannot convert to integer\n",
    "pd.to_numeric(tmdbDataSet['status'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melting and pivoting of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  AveragePrice  Total Volume  Total Bags  Small Bags  Large Bags  \\\n",
      "0  2015-12-27          1.33      64236.62     8696.87     8603.62       93.25   \n",
      "1  2015-12-20          1.35      54876.98     9505.56     9408.07       97.49   \n",
      "2  2015-12-13          0.93     118220.22     8145.35     8042.21      103.14   \n",
      "3  2015-12-06          1.08      78992.15     5811.16     5677.40      133.76   \n",
      "4  2015-11-29          1.28      51039.60     6183.95     5986.26      197.69   \n",
      "\n",
      "   XLarge Bags          type  year  region avocados_variety     4046  \n",
      "0          0.0  conventional  2015  Albany             4046  1036.74  \n",
      "1          0.0  conventional  2015  Albany             4046   674.28  \n",
      "2          0.0  conventional  2015  Albany             4046    794.7  \n",
      "3          0.0  conventional  2015  Albany             4046     1132  \n",
      "4          0.0  conventional  2015  Albany             4046   941.48  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 164241 entries, 0 to 164240\n",
      "Data columns (total 12 columns):\n",
      "Date                164241 non-null object\n",
      "AveragePrice        164241 non-null float64\n",
      "Total Volume        164241 non-null float64\n",
      "Total Bags          164241 non-null float64\n",
      "Small Bags          164241 non-null float64\n",
      "Large Bags          164241 non-null float64\n",
      "XLarge Bags         164241 non-null float64\n",
      "type                164241 non-null object\n",
      "year                164241 non-null int64\n",
      "region              164241 non-null object\n",
      "avocados_variety    164241 non-null object\n",
      "4046                164241 non-null object\n",
      "dtypes: float64(6), int64(1), object(5)\n",
      "memory usage: 15.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Melting of dataset\n",
    "avocadoDataSet_melt_4770 = pd.melt(avocadoDataSet, id_vars=['Date', 'AveragePrice', 'Total Volume', '4046', '4225',\n",
    "       'Total Bags', 'Small Bags', 'Large Bags', 'XLarge Bags', 'type', 'year',\n",
    "       'region'], var_name='avocados_variety', value_name='4770')\n",
    "\n",
    "avocadoDataSet_melt_4225 = pd.melt(avocadoDataSet_melt_4770, id_vars=['Date', 'AveragePrice', 'Total Volume', '4046',\n",
    "       'Total Bags', 'Small Bags', 'Large Bags', 'XLarge Bags', 'type', 'year',\n",
    "       'region'], var_name='avocados_variety', value_name='4225')\n",
    "\n",
    "avocadoDataSet_melt_4046 = pd.melt(avocadoDataSet_melt_4225, id_vars=['Date', 'AveragePrice', 'Total Volume',\n",
    "       'Total Bags', 'Small Bags', 'Large Bags', 'XLarge Bags', 'type', 'year',\n",
    "       'region'], var_name='avocados_variety', value_name='4046')\n",
    "\n",
    "print(avocadoDataSet_melt_4046.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type         conventional      organic\n",
      "Date                                  \n",
      "2015-01-04  316404.287361  7464.354514\n",
      "2015-01-11  291850.210602  8419.956667\n",
      "2015-01-18  294349.616713  8347.219074\n",
      "2015-01-25  292685.403981  6873.669722\n",
      "2015-02-01  469624.264699  8962.093333\n"
     ]
    }
   ],
   "source": [
    "# Pivoting of dataset\n",
    "avocadoDataSet_melt_4046['4046'] = pd.to_numeric(avocadoDataSet_melt_4046['4046'], errors='coerce')\n",
    "avocadoDataSet_pivot = avocadoDataSet_melt_4046.pivot_table(index=['Date'], \n",
    "columns='type', values='4046', aggfunc=np.mean)\n",
    "\n",
    "print(avocadoDataSet_pivot.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type                          conventional       organic\n",
      "Date       avocados_variety                             \n",
      "2015-01-04 4046              601242.840926  11687.876481\n",
      "           4225              239503.592037   5218.735556\n",
      "           avocados_variety    4497.500000   4497.500000\n",
      "2015-01-11 4046              561008.763704  13512.810185\n",
      "           4225              214260.131235   5942.074259\n"
     ]
    }
   ],
   "source": [
    "# Pivoting of dataset\n",
    "# If we also want to see the variety along with the type\n",
    "avocadoDataSet_melt_4046['4046'] = pd.to_numeric(avocadoDataSet_melt_4046['4046'], errors='coerce')\n",
    "avocadoDataSet_pivot = avocadoDataSet_melt_4046.pivot_table(index=['Date', 'avocados_variety'], \n",
    "columns='type', values='4046', aggfunc=np.mean)\n",
    "\n",
    "print(avocadoDataSet_pivot.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting columns\n",
    "\n",
    "We can even split a single column into multiple column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = {1: 'JAN', 2: 'FEB', 3: 'MAR', \n",
    "         4: 'APR',5: 'MAY', 6: 'JUNE',7: 'JULY', 8: 'AUG', 9: 'SEP', 10: 'OCT', 11: 'NOV', 12: 'DEC' }\n",
    "avocadoDataSet['Month'] = avocadoDataSet.Date.str.split('-').str.get(1)\n",
    "avocadoDataSet['Month'] = pd.to_numeric(avocadoDataSet['Month'], errors='coerce')\n",
    "avocadoDataSet['Month'] = avocadoDataSet['Month'].map(month)\n",
    "print(avocadoDataSet.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading multiple files in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = '*.csv'\n",
    "csv_files = glob.glob(pattern)\n",
    "dataset = pd.read_csv(csv_files[1])\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmdbDataSet.info())\n",
    "print(avocadoDataSet.info())\n",
    "\n",
    "avocadoDataSet.drop_duplicates()\n",
    "tmdbDataSet.drop_duplicates()\n",
    "\n",
    "print(tmdbDataSet.info())\n",
    "print(avocadoDataSet.info())\n",
    "\n",
    "# Since there are no duplicates rows in both of the datsets\n",
    "# Therefore we can't see any chnage in rows returned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Expressions and Apply function in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog = re.compile('\\d{3}-\\d{3}-\\d{4}')\n",
    "result = prog.match('123-456-7890')\n",
    "print(bool(result))\n",
    "\n",
    "result = prog.match('1123-456-7890')\n",
    "print(bool(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = re.findall('\\d+', 'Out of 3 houses, 2 houses have 4 people statying.')\n",
    "print(matches)\n",
    "\n",
    "# Observation\n",
    "# The above code will find out all the numbers in the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_avocado_type(value):\n",
    "    if value == 'conventional':\n",
    "        return 1\n",
    "    elif value == 'organic':\n",
    "        return 0\n",
    "\n",
    "avocadoDataSet['type_coded'] = avocadoDataSet.type.apply(encode_avocado_type)\n",
    "\n",
    "print(avocadoDataSet.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avocadoDataSet['Date_replace'] = avocadoDataSet['Date'].apply(lambda x: x.replace('-', '/'))\n",
    "\n",
    "avocadoDataSet['Date_find'] = avocadoDataSet['Date'].apply(lambda x: re.findall('\\d', x))\n",
    "\n",
    "print(avocadoDataSet.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling missing data in the column\n",
    "\n",
    "In tmdbDataSet, for column runtime there are two rows which doesn't have any data. We can either delete these two rows or we can add data to these two rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two rows which doesn't have data for runtime column\n",
    "print(tmdbDataSet[tmdbDataSet['runtime'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_mean = tmdbDataSet.runtime.mean()\n",
    "tmdbDataSet['runtime'] = tmdbDataSet['runtime'].fillna(runtime_mean)\n",
    "\n",
    "print(tmdbDataSet.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward fill and backward fill\n",
    "tmdbDataSet['homepage_ffill'] = tmdbDataSet['homepage'].fillna(method='ffill')\n",
    "tmdbDataSet['homepage_bfill'] = tmdbDataSet['homepage'].fillna(method='bfill')\n",
    "print(tmdbDataSet[tmdbDataSet['homepage_ffill'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdbDataSet['homepage_ffill']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdbDataSet['homepage_bfill']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
